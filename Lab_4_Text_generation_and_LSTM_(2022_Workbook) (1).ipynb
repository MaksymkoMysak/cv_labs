{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-tiVIhwDZgF"
   },
   "source": [
    "# –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —Ç–µ–∫—Å—Ç—É\n",
    "\n",
    "–£ —Ü—ñ–π —Ä–æ–±–æ—Ç—ñ –º–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—î–º–æ –º–æ–≤–Ω—É –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó —Ç–µ–∫—Å—Ç—É. –á—ó –±–∞–∂–∞–Ω–æ –≤–∏–∫–æ–Ω—É–≤–∞—Ç–∏ –ø—ñ—Å–ª—è –ø–µ—Ä–µ–≥–ª—è–¥—É [–ª–µ–∫—Ü—ñ—ó 4.2](https://youtu.be/yAUCnoKW2QI)\n",
    "\n",
    "–£ –∫–ª–∞—Å–∏—á–Ω–æ—ó –º–æ–≤–Ω–æ—ó –º–æ–¥–µ–ª—ñ —î –¥–≤–∞ –≤–∑–∞—î–º–æ–ø–æ–≤'—è–∑–∞–Ω—ñ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è:\n",
    "\n",
    "1. –û—Ü—ñ–Ω–∏—Ç–∏ –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å –≤—Ö—ñ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç—É.\n",
    "2. –ú–∞—é—á–∏ –ø–µ–≤–Ω–∏–π –ø—Ä–µ—Ñ—ñ–∫—Å –Ω–∞ –≤—Ö–æ–¥—ñ, –≤–∏–¥–∞—Ç–∏ –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ —Å–ª–æ–≤–∞.\n",
    "\n",
    "–î–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó —Ç–µ–∫—Å—Ç—É –Ω–∞–º —ñ–¥–µ–∞–ª—å–Ω–æ –ø—ñ–¥—Ö–æ–¥–∏—Ç—å –¥—Ä—É–≥–µ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5cdtYXg9ARX"
   },
   "source": [
    "## –ü–æ—á–∞—Ç–æ–∫ —Ä–æ–±–æ—Ç–∏\n",
    "\n",
    "–ë—É–¥—å –ª–∞—Å–∫–∞, –∑–∞–ø–æ–≤–Ω—ñ—Ç—å –ø–æ–ª—è `EMAIL`, `NAME` —Ç–∞ `GROUP` –Ω–∏–∂—á–µ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vuKrzAhF9DS9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'YES!'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################‚Ññ‚Ññ‚Ññ‚Ññ‚Ññ‚Ññ‚Ññ‚Ññ###########################\n",
    "# FILL-IN:\n",
    "#-----------------------------------------------------------------------\n",
    "EMAIL = \"maksym.mysak.knm.2018@lpnu.ua\"    # –Ω–∞–ø—Ä–∏–∫–ª–∞–¥, oleksiy.syvokon@lpnu.ua\n",
    "NAME = \"–ú–∞–∫—Å–∏–º –ú–∏—Å–∞–∫\"            # –Ω–∞–ø—Ä–∏–∫–ª–∞–¥, \"–û–ª–µ–∫—Å—ñ–π –°–∏–≤–æ–∫–æ–Ω—å\"\n",
    "GROUP = \"–ö–ù-409\"  # –ø—ñ–¥—Å—Ç–∞–≤—Ç–µ –≤–∞—à—É –≥—Ä—É–ø—É, –∑–∞–ª–∏—à—Ç–µ –ö–ù-400, —è–∫—â–æ –∂–æ–¥–Ω–∞ –Ω–µ –ø—ñ–¥—Ö–æ–¥–∏—Ç—å\n",
    "#####################################‚Ññ‚Ññ‚Ññ‚Ññ‚Ññ‚Ññ‚Ññ‚Ññ###################################\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def report(stage, answer):\n",
    "    if answer is ...:\n",
    "        raise ValueError(\"Please, implement a solution\")\n",
    "\n",
    "    payload = {\"email\": EMAIL, \"name\": NAME, \"group\": GROUP}\n",
    "    payload[\"stage\"] = str(stage)\n",
    "    payload[\"answer\"] = str(answer)\n",
    "    payload[\"lab\"] = \"lab4\"\n",
    "    \n",
    "    r = requests.post(\"http://134.209.248.229:8082/report\", json=payload)\n",
    "    if not r.ok:\n",
    "        print(\"–ü—Ä–æ–±–ª–µ–º–∞ –∑ —Å–µ—Ä–≤–µ—Ä–æ–º :( –°–ø—Ä–æ–±—É–π—Ç–µ –ø—ñ–∑–Ω—ñ—à–µ –∞–±–æ –Ω–∞–ø–∏—à—ñ—Ç—å –≤–∏–∫–ª–∞–¥–∞—á–µ–≤—ñ\")\n",
    "    \n",
    "    return answer\n",
    "\n",
    "assert EMAIL, \"–ó–∞–ø–æ–≤–Ω—ñ—Ç—å –ø–æ–ª–µ EMAIL\"\n",
    "assert NAME, \"–ó–∞–ø–æ–≤–Ω—ñ—Ç—å –ø–æ–ª–µ NAME\"\n",
    "report(\"Ready\", \"YES!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIrY-_DL9XRv"
   },
   "source": [
    "### –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ\n",
    "\n",
    "–¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –º–æ–≤–Ω–æ—ó –º–æ–¥–µ–ª—ñ –∑ –Ω—É–ª—è –∑–∞–π–º–∞—î –±–∞–≥–∞—Ç–æ —á–∞—Å—É: –≤—ñ–¥ –∫—ñ–ª—å–∫–æ—Ö –≥–æ–¥–∏–Ω –¥–æ –∫—ñ–ª—å–∫–æ—Ö –¥–Ω—ñ–≤ –¥–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö —Ç–∞ —Å–µ—Ä–µ–¥–Ω—ñ—Ö –º–æ–¥–µ–ª–µ–π –π –¥–æ –∫—ñ–ª—å–∫–æ—Ö –º—ñ—Å—è—Ü—ñ–≤ —á–∏ –Ω–∞–≤—ñ—Ç—å —Ä–æ–∫—ñ–≤ –¥–ª—è –≤–µ–ª–∏–∫–∏—Ö (–∑–≤–∏—á–∞–π–Ω–æ, –∑–∞ —Ä–∞—Ö—É–Ω–æ–∫ .\n",
    "\n",
    "–î–ª—è —Ü—ñ—î—ó —Ä–æ–±–æ—Ç–∏ —è –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ –Ω–∞—Ç—Ä–µ–Ω—É–≤–∞–≤ –Ω–µ–≤–µ–ª–∏—á–∫—É LSTM –º–æ–¥–µ–ª—å. –¢—Ä–µ–Ω—É–≤–∞–ª—å–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏ –±—É–ª–∏ —Ä–µ—á–µ–Ω–Ω—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é, –Ω–∞–±—Ä–∞–Ω—ñ –∑ —ñ–Ω—Ç–µ—Ä–Ω–µ—Ç—É –Ω–∞–≤–º–∞–Ω–Ω—è. –¢–µ–∫—Å—Ç –±—É–≤ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–π –¥–æ –Ω–∏–∂–Ω—å–æ–≥–æ —Ä–µ–≥—ñ—Å—Ç—Ä—É. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Oadzovl02gxh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget http://134.209.248.229:8081/oscar-epoch3.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T4su2VnEGSiU"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZpeVt8kn76PY"
   },
   "outputs": [],
   "source": [
    "model_state = torch.load(\"oscar-epoch3.pt\", map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uugdVo_l8BK7"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LstmLM(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, dim_embed, dim_hidden, num_layers, dropout=0.5, tie_weights=False):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.embed = nn.Embedding(vocab_size, dim_embed)\n",
    "        self.rnn = nn.LSTM(dim_embed, dim_hidden, num_layers)\n",
    "        self.linear = nn.Linear(dim_hidden, vocab_size)\n",
    "\n",
    "        if tie_weights:\n",
    "            if dim_hidden != dim_embed:\n",
    "                raise ValueError('When using the tied flag, dim_hidden must be equal to dim_embed')\n",
    "            self.linear.weight = self.embed.weight\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        nn.init.uniform_(self.embed.weight, -initrange, initrange)\n",
    "        nn.init.zeros_(self.linear.weight)\n",
    "        nn.init.uniform_(self.linear.weight, -initrange, initrange)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        emb = self.dropout(self.embed(input))\n",
    "        output, hidden = self.rnn(emb, hidden)\n",
    "        output = self.dropout(output)\n",
    "        decoded = self.linear(output)\n",
    "        decoded = decoded.view(-1, self.vocab_size)\n",
    "        return F.log_softmax(decoded, dim=1), hidden\n",
    "\n",
    "    def init_hidden(self, bsz=1):\n",
    "        weight = next(self.parameters())\n",
    "        return (weight.new_zeros(self.num_layers, bsz, self.dim_hidden),\n",
    "                weight.new_zeros(self.num_layers, bsz, self.dim_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H0NgmBJ89UvA"
   },
   "outputs": [],
   "source": [
    "model = LstmLM(vocab_size=32000,\n",
    "               dim_embed=512,\n",
    "               dim_hidden=512,\n",
    "               num_layers=3,\n",
    "               dropout=0.3,\n",
    "               tie_weights=True)\n",
    "model.load_state_dict(model_state)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QNW6QMBXQf0Y"
   },
   "source": [
    "### –°–ª–æ–≤–Ω–∏–∫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_hRjqHWOlIV"
   },
   "source": [
    "–ó–∞–≤–∞–Ω—Ç–∞–∂–∏–º–æ —Å–ª–æ–≤–Ω–∏–∫, –∑ —è–∫–∏–º —Ç—Ä–µ–Ω—É–≤–∞–ª–∞—Å—è –º–æ–¥–µ–ª—å:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kgLkneSq-0Ps"
   },
   "outputs": [],
   "source": [
    "!wget http://134.209.248.229:8081/bpe.dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-wYEN2JPrg8"
   },
   "source": [
    "–ö–ª–∞—Å `Vocab` –¥–æ–ø–æ–º–æ–∂–µ –∑—Ä—É—á–Ω–æ –≤–∏–∫–æ–Ω—É–≤–∞—Ç–∏ —Ç–∞–∫—ñ —á–∞—Å—Ç—ñ –æ–ø–µ—Ä–∞—Ü—ñ—ó:\n",
    "\n",
    "1. `Vocab.word2idx()` - –æ—Ç—Ä–∏–º–∞—Ç–∏ —ñ–Ω–¥–µ–∫—Å —Å–ª–æ–≤–∞\n",
    "2. `Vocab.idx2word()` - –æ—Ç—Ä–∏–º–∞—Ç–∏ —Å–ª–æ–≤–æ –∑–∞ —ñ–Ω–¥–µ–∫—Å–æ–º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lsyV4GVu-X30"
   },
   "outputs": [],
   "source": [
    "class Vocab(object):\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = []\n",
    "\n",
    "    @classmethod\n",
    "    def from_file(cls, path):\n",
    "        d = Vocab()\n",
    "        with open(path) as f:\n",
    "            for word in f:\n",
    "                d.add_word(word.rstrip(\"\\n\"))\n",
    "        return d\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2idx:\n",
    "            self.idx2word.append(word)\n",
    "            self.word2idx[word] = len(self.idx2word) - 1\n",
    "        return self.word2idx[word]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx2word)\n",
    "\n",
    "vocab = Vocab.from_file(\"bpe.dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mIUF4cnFQP_v"
   },
   "outputs": [],
   "source": [
    "# –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞\n",
    "vocab.word2idx[\"the\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7WGu5ORJQYkm"
   },
   "outputs": [],
   "source": [
    "vocab.idx2word[22586]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S3Uh8W7wMpwE"
   },
   "source": [
    "## –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –º–æ–¥–µ–ª—ñ -- –æ–¥–∏–Ω –∫—Ä–æ–∫ —ñ—Ç–µ—Ä–∞—Ü—ñ—ó"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_LiBLRgyNu32"
   },
   "source": [
    "–ú–∏ –≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏–º–µ–º–æ —Ç–µ–∫—Å—Ç –≤ —Ü–∏–∫–ª—ñ —Ç–æ–∫–µ–Ω –∑–∞ —Ç–æ–∫–µ–Ω–æ–º, –∑–ª—ñ–≤–∞ –Ω–∞–ø—Ä–∞–≤–æ.–ê–ª–µ –¥–ª—è –ø–æ—á–∞—Ç–∫—É —Ä–æ–∑–±–µ—Ä–µ–º–æ, —è–∫ –≤–∏–≥–ª—è–¥–∞—î –æ–¥–∏–Ω –∫—Ä–æ–∫ —Ç–∞–∫–æ–≥–æ —Ü–∏–∫–ª—É. \n",
    "\n",
    "–†–µ–∫—É—Ä–µ–Ω—Ç–Ω—ñ –º–µ—Ä–µ–∂—ñ –∑–±–µ—Ä—ñ–≥–∞—é—Ç—å —Å–≤–æ—é \"–ø–∞–º'—è—Ç—å\" –∞–±–æ \"—Å—Ç–∞–Ω\" —É –≤–µ–∫—Ç–æ—Ä—ñ (—É –≤–∏–ø–∞–¥–∫—É –∑ LSTM, –¥–≤–æ—Ö –≤–µ–∫—Ç–æ—Ä–∞—Ö). –¶–µ–π —Å—Ç–∞–Ω –º—ñ—Å—Ç–∏—Ç—å –≤ —Å–æ–±—ñ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –≤–∂–µ –ø–æ–±–∞—á–µ–Ω—ñ —Ç–æ–∫–µ–Ω–∏. \n",
    "\n",
    "–û—Å–∫—ñ–ª—å–∫–∏ –Ω–∞ –ø–µ—Ä—à–æ–º—É –∫—Ä–æ—Ü—ñ –º–∏ —â–µ –±–∞—á–∏–ª–∏ –∂–æ–¥–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω—É, —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î–º–æ \"–ø–∞–º'—è—Ç—å\" –Ω—É–ª—è–º–∏ —Ç–∞ –∑–±–µ—Ä–µ–∂–µ–º–æ —ó—ó —É –∑–º—ñ–Ω–Ω—ñ–π `hidden`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EN12UkTcM5ub"
   },
   "outputs": [],
   "source": [
    "hidden = model.init_hidden()\n",
    "hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9cbLyy3N-u9"
   },
   "source": [
    "–ù–∞ –∫–æ–∂–Ω–æ–º—É –∫—Ä–æ—Ü—ñ –Ω–∞ –≤—Ö—ñ–¥ –º–æ–¥–µ–ª—ñ –ø–æ–¥–∞—î–º–æ –Ω–∞—Å—Ç—É–ø–Ω–∏–π —Ç–æ–∫–µ–Ω —Ä–µ—á–µ–Ω–Ω—è. –ü–æ—á–∏–Ω–∞—î–º–æ –∑—ñ —Å–ø–µ—Ü—ñ–∞–ª—å–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω—É `<BOS>` (\"begin of sentence\"):\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CjeJgPqtObeQ"
   },
   "outputs": [],
   "source": [
    "# –ó–Ω–∞–π–¥–µ–º–æ —ñ–Ω–¥–µ–∫—Å —Ç–æ–∫–µ–Ω–∞ –≤ —Å–ª–æ–≤–Ω–∏–∫—É\n",
    "index = vocab.word2idx[\"<BOS>\"]\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y6z8l1TlRQa-"
   },
   "outputs": [],
   "source": [
    "# –§–æ—Ä–º—É—î–º–æ –≤—Ö—ñ–¥–Ω–∏–π –±–∞—Ç—á. –ú–∞–π–∂–µ –∑–∞–≤–∂–¥–∏ –¥–ª—è –±—ñ–ª—å—à–æ—ó –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ\n",
    "# –Ω–µ–π—Ä–æ–Ω–Ω—ñ –º–µ—Ä–µ–∂—ñ –æ—á—ñ–∫—É—é—Ç—å –Ω–∞ –≤—Ö—ñ–¥ –∫—ñ–ª—å–∫–∞ –Ω–µ–∑–∞–ª–µ–∂–Ω–∏—Ö —Ä–µ—á–µ–Ω—å \n",
    "# (–∞–±–æ –∑–æ–±—Ä–∞–∂–µ–Ω—å —É –≤–∏–ø–∞–¥–∫—É –∑ –∫–æ–º–ø'—é—Ç–µ—Ä–Ω–∏–º –∑–æ—Ä–æ–º)\n",
    "#\n",
    "# –í –Ω–∞—à—ñ–π —Ä–æ–±–æ—Ç—ñ –º–∏ –∑–∞–≤–∂–¥–∏ –ø—Ä–∞—Ü—é—î–º–æ –ª–∏—à–µ –∑ –æ–¥–Ω–∏–º —Ä–µ—á–µ–Ω–Ω—è–º,\n",
    "# —Ç–æ–∂ —Ä–æ–∑–º—ñ—Ä –±–∞—Ç—á–∞ –¥–æ—Ä—ñ–≤–Ω—é—î –æ–¥–∏–Ω—Ü—ñ. –ê–ª–µ –≤—Å–µ –æ–¥–Ω–æ –º–∞—î–º–æ\n",
    "# –æ—Ñ–æ—Ä–º–∏—Ç–∏ –≤—Ö—ñ–¥ —è–∫ –º–∞—Ç—Ä–∏—Ü—é:\n",
    "input_ = torch.LongTensor([[index]])\n",
    "input_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vSiBQkJJSGue"
   },
   "outputs": [],
   "source": [
    "# –ù–∞—Ä–µ—à—Ç—ñ —Ä–æ–±–∏–º–æ –∫—Ä–æ–∫ LSTM\n",
    "# –í—Ö—ñ–¥: –ø–æ—Ç–æ—á–Ω–∏–π —Å—Ç–∞–Ω (–ø–∞–º'—è—Ç—å) —Ç–∞ –≤—Ö—ñ–¥–Ω–∏–π —Ç–æ–∫–µ–Ω\n",
    "# –í–∏—Ö—ñ–¥: —Ä–æ–∑–ø–æ–¥—ñ–ª –ø–æ —Å–ª–æ–≤–Ω–∏–∫—É (–ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞) —Ç–∞ –æ–Ω–æ–≤–ª–µ–Ω–∏–π —Å—Ç–∞–Ω\n",
    "output, hidden = model(input_, hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNoTYS-1Sr2y"
   },
   "source": [
    "–ü–µ—Ä–µ–≤—ñ—Ä–∏–º–æ –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç–Ω–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª, —è–∫–∏–π –≤–∏–¥–∞–ª–∞ –º–æ–¥–µ–ª—å:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dMCovI7uS1N8"
   },
   "outputs": [],
   "source": [
    "# –†–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å –∑–±—ñ–≥–∞—î—Ç—å—Å—è –∑ —Ä–æ–∑–º—ñ—Ä–æ–º —Å–ª–æ–≤–Ω–∏–∫–∞\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_1H8iIaSTHJl"
   },
   "outputs": [],
   "source": [
    "# –ú–æ–¥–µ–ª—å –ø–æ–≤–µ—Ä—Ç–∞—î –ª–æ–≥–∞—Ä–∏—Ñ–º–∏ –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç–µ–π\n",
    "# –Ø–∫—â–æ –º–∏ –ø—Ä–æ–µ–∫—Å–ø–æ–Ω–µ–Ω—Ü—ñ–æ–Ω—É—î–º–æ —ó—Ö, –æ—Ç—Ä–∏–º–∞—î–º–æ \"–∑–≤–∏—á–∞–π–Ω—ñ\" –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ\n",
    "probs = output.squeeze().exp()\n",
    "\n",
    "# –°—É–º–∞ –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç–µ–π –º–∞—î –¥–æ—Ä—ñ–≤–Ω—é–≤–∞—Ç–∏ 1.0\n",
    "probs.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kA1iznWPTdK4"
   },
   "outputs": [],
   "source": [
    "# –ö–æ–∂–Ω–æ–º—É —Å–ª–æ–≤—É –≤ —Å–ª–æ–≤–Ω–∏–∫—É –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î —Å–≤–æ—è –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å –±—É—Ç–∏ –ø–æ–±–∞—á–µ–Ω–∏–º\n",
    "# –ø—ñ—Å–ª—è –∑–∞–¥–∞–Ω–æ–≥–æ –ø—Ä–µ—Ñ—ñ–∫—Å–∞. –ü—Ä–µ—Ñ—ñ–∫—Å–æ–º —É –Ω–∞—Å –∑–∞—Ä–∞–∑ –±—É–≤ –ª–∏—à–µ –æ–¥–Ω–∏ —Ç–æ–∫–µ–Ω <BOS>\n",
    "\n",
    "# –Ø–∫–∞ –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å, —â–æ —Ä–µ—á–µ–Ω–Ω—è –ø–æ—á–Ω–µ—Ç—å—Å—è –∑—ñ —Å–ª–æ–≤–∞ —è?\n",
    "probs[vocab.word2idx[\"—è\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kaoCr91RTw4Z"
   },
   "source": [
    "–¢–µ–ø–µ—Ä, –∫–æ–ª–∏ –º–∞—î–º–æ –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç–Ω–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª –ø–æ —Å–ª–æ–≤–Ω–∏–∫—É, –º–æ–∂–µ–º–æ –æ–±—Ä–∞—Ç–∏ —Å–ª–æ–≤–æ, —è–∫–µ –≤–≤–∞–∂–∞—Ç–∏–º–µ–º–æ –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–∏–º. –¢—É—Ç –º–æ–∂–ª–∏–≤—ñ –∫—ñ–ª—å–∫–∞ —Å—Ç—Ä–∞—Ç–µ–≥—ñ–π, —è–∫—ñ –º–∏ —Ä–æ–∑–≥–ª—è–Ω–µ–º–æ –≤ –Ω–∞—Å—Ç—É–ø–Ω–∏—Ö —Ä–æ–∑–¥—ñ–ª–∞—Ö."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUbajoW_-ClA"
   },
   "source": [
    "## Greedy decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9yOkcB3FUd3N"
   },
   "source": [
    "–ù–∞–π–ø—Ä–æ—Å—Ç—ñ—à–∏–π (–∞–ª–µ –π –Ω–µ –¥—É–∂–µ —Ü—ñ–∫–∞–≤–∏–π) —Å–ø–æ—Å—ñ–± -- —Ü–µ –∑–∞–≤–∂–¥–∏ –æ–±–∏—Ä–∞—Ç–∏ —Ç–æ–∫–µ–Ω –∑ –Ω–∞–π–±—ñ–ª—å—à–æ—é –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—é:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wG7QsAjPUoHW"
   },
   "outputs": [],
   "source": [
    "next_token_id = probs.argmax()\n",
    "next_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z87pe4Y0VJ1W"
   },
   "outputs": [],
   "source": [
    "probs[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WaZRZWpAUtNY"
   },
   "outputs": [],
   "source": [
    "vocab.idx2word[next_token_id]  # –ù–∞—à –ø–µ—Ä—à–∏–π –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–∏–π —Ç–æ–∫–µ–Ω"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L5a6IGTg-x8e"
   },
   "outputs": [],
   "source": [
    "report(\"First generated token\", vocab.idx2word[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVB5pXOoX29S"
   },
   "source": [
    "–ó–±–µ—Ä–µ–º–æ –Ω–∞—à –∫–æ–¥ –¥–æ–∫—É–ø–∏ —Ç–∞ –¥–æ–¥–∞–º–æ —Ü–∏–∫–ª. –í —Ü–∏–∫–ª—ñ –º–∏ –ø—Ä–æ–¥–æ–≤–∂—É–≤–∞—Ç–∏–º–µ–º–æ –≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ —Ç–µ–∫—Å—Ç —Ç–æ–∫–µ–Ω –∑–∞ —Ç–æ–∫–µ–Ω–æ–º, –ø–æ–∫–∏ –Ω–µ –Ω–∞—Å—Ç–∞–Ω–µ –æ–¥–Ω–∞ –∑ –¥–≤–æ—Ö —É–º–æ–≤:\n",
    "1. –ú–æ–¥–µ–ª—å –≤–∏–¥–∞–ª–∞ —Å–ø–µ—Ü–∞–ª—å–Ω–∏–π —Ç–æ–∫–µ–Ω `<EOS>` (end of sentence)\n",
    "2. –î–æ–≤–∂–∏–Ω–∞ –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç—É –ø–µ—Ä–µ–≤–∏—â–∏–ª–∞ –ø–µ–≤–Ω–∏–π –ø–æ—Ä—ñ–≥ `max_len`\n",
    "\n",
    "–£ —Ö–æ—Ä–æ—à–æ—ó –º–æ–¥–µ–ª—ñ –≤ –±—ñ–ª—å—à–æ—Å—Ç—ñ –≤–∏–ø–∞–¥–∫—ñ–≤ –º–∞—î —Å–ø—Ä–∞—Ü—å–æ–≤—É–≤–∞—Ç–∏ –ø–µ—Ä—à–∞ —É–º–æ–≤–∞ –∑—É–ø–Ω–∫–∏. –ü—Ä–æ—Ç–µ —ñ–Ω–æ–¥—ñ –º–æ–¥–µ–ª—å –º–æ–∂–µ –≤–ø–∞—Å—Ç–∏ –≤ –±–µ–∑–∫—ñ–Ω—á–µ–Ω–∏–π —Ü–∏–∫–ª. –©–æ–± —Ü—å–æ–º—É –∑–∞–ø–æ–±—ñ–≥—Ç–∏, –º–∞—î–º–æ –¥—Ä—É–≥—É —É–º–æ–≤—É."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cG8nI5WG-Qb5"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def greedy_decode(model, vocab, max_len=50):\n",
    "    result = []\n",
    "    EOS_TOKEN = \"<EOS>\"\n",
    "    hidden = model.init_hidden()\n",
    "    start_index = vocab.word2idx[\"<BOS>\"]\n",
    "    input_ = torch.LongTensor([[start_index]])\n",
    "\n",
    "    while len(result) < max_len:\n",
    "\n",
    "        # –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç–Ω–µ–π –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞\n",
    "        output, hidden = model(input_, hidden)\n",
    "        probs = output.squeeze().exp()\n",
    "        \n",
    "        # –û–±–∏—Ä–∞—î–º–æ —Ç–æ–∫–µ–Ω, —â–æ –º–∞—î –Ω–∞–π–±—ñ–ª—å—à—É –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å\n",
    "        token_index = probs.argmax()\n",
    "\n",
    "        # –û–±—Ä–∞–Ω–∏–π —Ç–æ–∫–µ–Ω —Å—Ç–∞—î –Ω–∞—Å—Ç—É–ø–Ω–∏–º –≤—Ö—ñ–¥–Ω–∏–º —Ç–æ–∫–µ–Ω–æ–º –¥–ª—è –º–æ–¥–µ–ª—ñ\n",
    "        input_.fill_(token_index)\n",
    "        \n",
    "        # –î–æ–¥–∞—î–º–æ –æ–±—Ä–∞–Ω–∏–π —Ç–æ–∫–µ–Ω –≤ –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–∏–π —Ç–µ–∫—Å—Ç\n",
    "        token = vocab.idx2word[token_index]\n",
    "        if token == EOS_TOKEN:\n",
    "            break\n",
    "        result.append(token)\n",
    "        \n",
    "    return \"\".join(result)\n",
    "\n",
    "\n",
    "greedy_decode(model, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qv0i3pqdJ3Bn"
   },
   "outputs": [],
   "source": [
    "report(\"greedy decode\", greedy_decode(model, vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9GN1tc5kYsOk"
   },
   "source": [
    "### –ü—Ä–∏–º—ñ—Ç–∫–∞: Byte-pair encoding (BPE)\n",
    "\n",
    "–ù–∞—à–∞ –º–æ–¥–µ–ª—å –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î subword —Ç–æ–∫–µ–Ω—ñ–∑–∞—Ü—ñ—é, –∞ —Å–∞–º–µ byte-pair encoding (BPE). –í —Å—É—á–∞—Å–Ω–æ–º—É NLP —Ü–µ –Ω–∞–π—Ä–æ–∑–ø–æ–≤—Å—é–¥–∂–µ–Ω—ñ—à–∏–π —Å–ø–æ—Å—ñ–± —Ç–æ–∫–µ–Ω—ñ–∑–∞—Ü—ñ—ó. –î–µ—Ç–∞–ª—å–Ω–æ –º–æ–∂–µ—Ç–µ –ø–æ–¥–∏–≤–∏—Ç–∏—Å—è –≤ [—Ü—å–æ–º—É –≤—ñ–¥–µ–æ](https://www.youtube.com/watch?v=tOMjTCO0htA).\n",
    "\n",
    "–î–ª—è –Ω–∞—à–∏—Ö —Ü—ñ–ª–µ–π –∑–∞—Ä–∞–∑ –≤–∞–∂–ª–∏–≤–æ, —â–æ BPE –∑–∞–º—ñ–Ω—è—î –ø—Ä–æ–±—ñ–ª–∏ –Ω–∞ —Å–ø–µ—Ü—ñ–∞–ª—å–Ω—ñ Unicode-—Å–∏–º–≤–æ–ª–∏ \"‚ñÅ\" (–∑–≤–µ—Ä–Ω—ñ—Ç—å —É–≤–∞–≥—É, —Ü–µ –Ω–µ –∑–≤–∏—á–∞–π–Ω–∏–π —Å–∏–º–≤–æ–ª –ø—ñ–¥–∫—Ä–µ—Å–ª–µ–Ω–Ω—è \"_\"). –©–æ–± –æ—Ç—Ä–∏–º–∞—Ç–∏ —á–∏—Å—Ç–∏–π —Ç–µ–∫—Å—Ç, —Ç—Ä–µ–±–∞ –≤–∏–∫–æ–Ω–∞—Ç–∏ –Ω–∞—Å—Ç—É–ø–Ω—É –∑–∞–º—ñ–Ω—É:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "5S_BPCLY_V9h"
   },
   "outputs": [],
   "source": [
    "def bpe_decode(s):\n",
    "    result = s.replace(\"‚ñÅ\", \" \")\n",
    "    if result.startswith(\" \"):\n",
    "        result = result[1:]\n",
    "    return result\n",
    "\n",
    "bpe_decode(greedy_decode(model, vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vK0wKs4IAk4l"
   },
   "source": [
    "## Generic decoding function\n",
    "\n",
    "–û–±–∏—Ä–∞—Ç–∏ —Å–ª–æ–≤–æ –∑ –Ω–∞–π–±—ñ–ª—å—à–æ—é –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—é -- –Ω–µ –Ω–∞–π–∫—Ä–∞—â–∏–π –≤–∞—Ä—ñ–∞–Ω—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó —Ç–µ–∫—Å—Ç—É —Ö–æ—á–∞ –± —Ç–æ–º—É, —â–æ –≤—ñ–Ω –∑–∞–≤–∂–¥–∏ –¥–µ—Ç–µ—Ä–º—ñ–Ω–æ–≤–∞–Ω–æ –ø—Ä–∏–∑–≤–æ–¥–∏—Ç—å –¥–æ –æ–¥–Ω—ñ—î—ó –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ—Å—Ç—ñ. –ù–∏–∂—á–µ –º–∏ –ø–æ–¥–∏–≤–∏–º–æ—Å—è –Ω–∞ —Ü—ñ–∫–∞–≤—ñ—à—ñ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∏.\n",
    "\n",
    "–¶–∏–∫–ª –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –∑–∞–ª–∏—à–∏—Ç—å—Å—è —Ç–æ–π —Å–∞–º–∏–π, —â–æ —ñ –≤ `greedy_decode()`. –í—ñ–¥—Ä—ñ–∑–Ω—è—Ç–∏—Å—è –±—É–¥–µ –ª–∏—à–µ –æ–¥–∏–Ω —Ä—è–¥–æ–∫ -- —Ç–æ–π, –≤ —è–∫–æ–º—É –º–∏ –ø—Ä–∏–π–º–∞–ª–∏ —Ä—ñ—à–µ–Ω–Ω—è, —è–∫–µ —Å–ª–æ–≤–æ –æ–±—Ä–∞—Ç–∏. –î–ª—è –∑—Ä—É—á–Ω–æ—Å—Ç—ñ, –≤–∏–Ω–µ—Å–µ–º–æ —Ü–µ–π —Ä—è–¥–æ–∫ –≤ –æ–∫—Ä–µ–º—É —Ñ—É–Ω–∫—Ü—ñ—é. –¶—è —Ñ—É–Ω–∫—Ü—ñ—è –ø—Ä–∏–π–º–∞—Ç–∏–º–µ –Ω–∞ –≤—Ö—ñ–¥ –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç–Ω–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª –ø–æ —Å–ª–æ–≤–Ω–∏–∫—É —ñ –ø–æ–≤–µ—Ä—Ç–∞—î –æ–±—Ä–∞–Ω–∏–π —Ç–æ–∫–µ–Ω. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8KQ_8Mky9enZ"
   },
   "outputs": [],
   "source": [
    "def greedy_choice(probs):\n",
    "    return probs.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XmH11o729oQL"
   },
   "source": [
    "–§—É–Ω–∫—Ü—ñ—é –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó —Ç–∞–∫–æ–∂ —Ç—Ä–æ—Ö–∏ –ø–µ—Ä–µ—Ä–æ–±–∏–º–æ.\n",
    "\n",
    "–ü–æ-–ø–µ—Ä—à–µ, –¥–æ–¥–∞–º–æ –ø–∞—Ä–∞–º–µ—Ç—Ä `sample_fn` -- —Ü–µ –º–∞—î –±—É—Ç–∏ —Ñ—É–Ω–∫—Ü—ñ—è, —è–∫–∞ –æ–±–∏—Ä–∞—î —Å–ª–æ–≤–æ –∑ –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç–Ω–æ–≥–æ —Ä–æ–∑–ø–æ–¥—ñ–ª—É, –Ω–∞–ø—Ä–∏–∫–ª–∞–¥, `greedy_choice`.\n",
    "\n",
    "–ü–æ-–¥—Ä—É–≥–µ, –¥–ª—è –∑—Ä—É—á–Ω–æ—Å—Ç—ñ –≤–∏–∫–æ–Ω—É–≤–∞—Ç–∏–º–µ–º–æ BPE –¥–µ–∫–æ–¥—ñ–Ω–≥ –≤ —Å–µ—Ä–µ–¥–∏–Ω—ñ —Ñ—É–Ω–∫—Ü—ñ—ó –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7eEGscC5Amzw"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate(model, vocab, sample_fn, max_len=50, bpe_decoded=True):\n",
    "    result = []\n",
    "    EOS_TOKEN = \"<EOS>\"\n",
    "    hidden = model.init_hidden()\n",
    "    start_index = vocab.word2idx[\"<BOS>\"]\n",
    "    input_ = torch.LongTensor([[start_index]])\n",
    "    \n",
    "    while len(result) < max_len:\n",
    "\n",
    "        # –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç–Ω–µ–π –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞\n",
    "        output, hidden = model(input_, hidden)\n",
    "        probs = output.squeeze().exp()\n",
    "        \n",
    "        # –û–±–∏—Ä–∞—î–º–æ –Ω–∞—Å—Ç—É–ø–Ω–∏–π —Ç–æ–∫–µ–Ω\n",
    "        token_index = sample_fn(probs)     # <---------------- —Ü–µ–π —Ä—è–¥–æ–∫ –∑–º—ñ–Ω–µ–Ω–æ\n",
    "\n",
    "        # –û–±—Ä–∞–Ω–∏–π —Ç–æ–∫–µ–Ω —Å—Ç–∞—î –Ω–∞—Å—Ç—É–ø–Ω–∏–º –≤—Ö—ñ–¥–Ω–∏–º —Ç–æ–∫–µ–Ω–æ–º –¥–ª—è –º–æ–¥–µ–ª—ñ\n",
    "        input_.fill_(token_index)\n",
    "        \n",
    "        # –î–æ–¥–∞—î–º–æ –æ–±—Ä–∞–Ω–∏–π —Ç–æ–∫–µ–Ω –≤ –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–∏–π —Ç–µ–∫—Å—Ç\n",
    "        token = vocab.idx2word[token_index]\n",
    "        if token == EOS_TOKEN:\n",
    "            break\n",
    "        result.append(token)\n",
    "\n",
    "\n",
    "    result_str = \"\".join(result)            # <---------------- —Ü—ñ —Ä—è–¥–∫–∏ –∑–º—ñ–Ω–µ–Ω–æ\n",
    "    if bpe_decoded:\n",
    "        result_str = bpe_decode(result_str)\n",
    "\n",
    "    return result_str\n",
    "\n",
    "\n",
    "# –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞:\n",
    "generate(model, vocab, greedy_choice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GXHiIrfZAnpW"
   },
   "source": [
    "## Simple sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7bbdLT96Bd8c"
   },
   "source": [
    "–ü–µ—Ä—à–∏–π –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ -- —Ü–µ sampling. –¢—É—Ç –º–∏ –æ–±–∏—Ä–∞—î–º–æ –Ω–∞—Å—Ç—É–ø–Ω–∏–π —Ç–æ–∫–µ–Ω –≤–∏–ø–∞–¥–∫–æ–≤–æ, –∞–ª–µ –∑ —É—Ä–∞—Ö—É–≤–∞–Ω–Ω—è–º –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç–µ–π."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01Y-djIkAsGB"
   },
   "outputs": [],
   "source": [
    "def simple_sample(probs):\n",
    "    return torch.multinomial(probs, num_samples=1)[0]\n",
    "\n",
    "# –ó–≥–µ–Ω–µ—Ä—É—î–º–æ 10 —Ä–µ—á–µ–Ω—å\n",
    "for i in range(1, 11):\n",
    "    result = generate(model, vocab, simple_sample, allow_unk=False)\n",
    "    print(f\"#{i}: {result}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tsFQnhgBEyGH"
   },
   "source": [
    "## –ü–æ–ª—ñ–ø—à–µ–Ω–Ω—è —Å–µ–º–ø–ª—ñ–Ω–≥—É\n",
    "\n",
    "### –ó–∞–±–æ—Ä–æ–Ω–∞ `<UNK>`\n",
    "\n",
    "–Ü–Ω–æ–¥—ñ –Ω–∞—à–∞ –º–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä—É—î `<UNK>` —Ç–æ–∫–µ–Ω–∏. –¢–∞–∫—ñ —Ç–æ–∫–µ–Ω–∏ –≤–∞–∂–ª–∏–≤—ñ –≤ –¥–µ—è–∫–∏—Ö –≤–∏–ø–∞–¥–∫–∞—Ö.\n",
    "\n",
    "–ù–∞–ø—Ä–∏–∫–ª–∞–¥, –≤—ñ–∑—å–º–µ–º–æ –º–æ–¥–µ–ª—å –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–∫–ª–∞–¥—É, —è–∫–∞ –ø–µ—Ä–µ–∫–ª–∞–¥–∞—î –∑ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó –Ω–∞ –∞–Ω–≥–ª—ñ–π—Å—å–∫—É. –ù–∞ –≤—Ö—ñ–¥ –º–æ–¥–µ–ª—ñ –ø—Ä–∏—Ö–æ–¥–∏—Ç—å —Ä–µ—á–µ–Ω–Ω—è:\n",
    "\n",
    "```\n",
    "–ú–µ–Ω–µ –∑–≤–∞—Ç–∏ –û–ª–µ–∫—Å—ñ–π –°–∏–≤–æ–∫–æ–Ω—å.\n",
    "```\n",
    "\n",
    "–Ø–∫—â–æ –≤ —Å–ª–æ–≤–Ω–∏–∫—É –º–æ–¥–µ–ª—ñ –Ω–µ–º–∞—î —Å–ª–æ–≤–∞ \"–°–∏–≤–æ–∫–æ–Ω—å\", —Ç–æ –º–æ–¥–µ–ª—å –º–æ–∂–µ –∑–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ —Ç–æ–∫–µ–Ω `<UNK>`. –¶–µ —Å–∏–≥–Ω–∞–ª, —â–æ –ø–µ–≤–Ω—ñ —Å–ª–æ–≤–∞ –≤–æ–Ω–∞ –Ω–µ –º–æ–∂–µ –ø–µ—Ä–µ–∫–ª–∞—Å—Ç–∏. –í —Ç–∞–∫–æ–º—É –≤–∏–ø–∞–¥–∫—É –≤–∏—Ö—ñ–¥ –º–æ–¥–µ–ª—ñ –±—É–¥–µ –≤–∏–≥–ª—è–¥–∞—Ç–∏ —è–∫–æ—Å—å —Ç–∞–∫:\n",
    "\n",
    "```\n",
    "My name is Oleksiy <UNK>.\n",
    "```\n",
    "\n",
    "–í —Ç–∞–∫–æ–º—É –≤–∏–ø–∞–¥–∫—É, —è–∫ –ø—Ä–∞–≤–∏–ª–æ, –∑–∞–ø—É—Å–∫–∞—é—Ç—å –¥–æ–¥–∞—Ç–∫–æ–≤–∏–π postprocessing –º–æ–¥—É–ª—å, —è–∫–∏–π, —Å–∫–∞–∂—ñ–º–æ, –∫–æ–ø—ñ—é—î –Ω–µ–≤—ñ–¥–æ–º—ñ —Å–ª–æ–≤–∞ –∑ –≤—Ö—ñ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç—É:\n",
    "\n",
    "```\n",
    "My name is Oleksiy –°–∏–≤–æ–∫–æ–Ω—å.\n",
    "```\n",
    "\n",
    "–ù–µ —ñ–¥–µ–∞–ª—å–Ω–æ, –∞–ª–µ –∫—Ä–∞—â–µ –Ω—ñ–∂ –Ω—ñ—á–æ–≥–æ.\n",
    "\n",
    "–¢—Ä–æ—Ö–∏ —Ä–æ–∑—É–º–Ω—ñ—à–∞ —Å–∏—Å—Ç–µ–º–∞ –º–æ–≥–ª–∞ –± —Ä–æ–±–∏—Ç–∏ —Ç—Ä–∞–Ω—Å–ª—ñ—Ç–µ—Ä–∞—Ü—ñ—é.\n",
    "\n",
    "–û—Ç–∂–µ, `<UNK>` —Ç–æ–∫–µ–Ω–∏ –≤–∞–∂–ª–∏–≤—ñ –≤ –º–∞—à–∏–Ω–Ω–æ–º—É –ø–µ—Ä–µ–∫–ª–∞–¥—ñ. –û–¥–Ω–∞–∫ –≤–æ–Ω–∏ –Ω–µ–¥–æ—Ü—ñ–ª—å–Ω—ñ —É –≤—ñ–ª—å–Ω—ñ–π –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó —Ç–µ–∫—Å—Ç—É. –¢–æ–º—É –º–∏ –ø—Ä–æ—Å—Ç–æ –∑–∞–±–æ—Ä–æ–Ω–∏–º–æ —ó—Ö –≥–µ–Ω–µ—Ä–∞—Ü—ñ—é, –ø—Ä–∏–∑–Ω–∞—á–∏–≤—à–∏ —ó–º –Ω—É–ª—å–æ–≤—É –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XwJG_jGmBXCU"
   },
   "source": [
    "## Sampling with temperature\n",
    "\n",
    "–ú–∏ —Ç–∞–∫–æ–∂ –º–æ–∂–µ–º–æ –≤–ø–ª–∏–≤–∞—Ç–∏ –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—é –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∏ softmax.\n",
    "\n",
    "–ë—ñ–ª—å—à—ñ –∑–Ω–∞—á–µ–Ω–Ω—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∏ –ø—Ä–∏–∑–≤–æ–¥—è—Ç—å –¥–æ —Ç–æ–≥–æ, —â–æ —Ä—ñ–∑–Ω–∏—Ü—è –º—ñ–∂ –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—è–º–∏ —Ç–æ–∫–µ–Ω—ñ–≤ –∑–º–µ–Ω—à—É—î—Ç—å—Å—è, —Ç–æ–±—Ç–æ —Ä–æ–∑–ø–æ–¥—ñ–ª —Å—Ç–∞—î –±—ñ–ª—å—à —Ä—ñ–≤–Ω–æ–º—ñ—Ä–Ω–∏–º. –ù–∞ –ø—Ä–∞–∫—Ç–∏—Ü—ñ —Ü–µ –æ–∑–Ω–∞—á–∞—î, —â–æ –º–µ–Ω—à –π–º–æ–≤—ñ—Ä–Ω—ñ –≤–∞—Ä—ñ–∞–Ω—Ç–∏ –æ–±–∏—Ä–∞—Ç–∏–º—É—Ç—å—Å—è —á–∞—Å—Ç—ñ—à–µ —ñ –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–∏–π —Ç–µ–∫—Å—Ç –º–æ–∂–µ –±—É—Ç–∏ —Ü—ñ–∫–∞–≤—ñ—à–∏–º. –û–¥–Ω–∞–∫ —è–∫—â–æ –ø—Ä–æ–¥–æ–≤–∂—É–≤–∞—Ç–∏ –ø—ñ–¥–Ω—ñ–º–∞—Ç–∏ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É, —Ç–æ —Ç–µ–∫—Å—Ç —Å–ø–æ—á–∞—Ç–∫—É –≤—Ç—Ä–∞—Ç–∏—Ç—å –∑–≤'—è–∑–Ω—ñ—Å—Ç—å, –¥–∞–ª—ñ –ø–æ—á–Ω—É—Ç—å —Ä–æ–∑–ø–∞–¥–∞—Ç–∏—Å—è —Å–ª–æ–≤–∞ —Ç–∞ –≥—Ä–∞–º–∞—Ç–∏—á–Ω—ñ—Å—Ç—å.\n",
    "\n",
    "–ú–µ–Ω—à—ñ –∑–Ω–∞—á–µ–Ω–Ω—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∏ –∑–º—ñ–Ω—é—é—Ç—å —Ä–æ–∑–ø–æ–¥—ñ–ª —Ç–∞–∫–∏–º —á–∏–Ω–æ–º, —â–æ –æ—Å–Ω–æ–≤–Ω–∞ –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç–∞ –º–∞—Å–∞ –ø—Ä–∏–ø–∞–¥–∞—î –Ω–∞ –Ω–µ–≤–µ–ª–∏–∫—É –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–æ–ø–æ–≤–∏—Ö —Ç–æ–∫–µ–Ω—ñ–≤. –ü—Ä–∏ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ñ 0 –≤—Å—è –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å –¥—ñ—Å—Ç–∞–Ω–µ—Ç—å—Å—è –æ–¥–Ω–æ–º—É —Ç–æ–∫–µ–Ω—É –π —Å–µ–º–ø–ª—ñ–Ω–≥ –ø–µ—Ä–µ—Ç–≤–æ—Ä–∏—Ç—å—Å—è –Ω–∞ greedy decoding.\n",
    "\n",
    "–î–æ–¥–∞–º–æ –≤ —Ñ—É–Ω–∫—Ü—ñ—é `generate()` –ø–∞—Ä–∞–º–µ—Ç—Ä `temperature` —Ç–∞ –∑–≥–µ–Ω–µ—Ä—É—î–º–æ —Ç–µ–∫—Å—Ç–∏ –∑ —Ä—ñ–∑–Ω–æ—é —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–æ—é:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7meVwePeAsiu"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate(model, vocab, sample_fn, max_len=50, min_len=0, allow_unk=True, temperature=1.0):\n",
    "    result = []\n",
    "    hidden = model.init_hidden(1)\n",
    "    # input_ = torch.LongTensor([[random.randint(0, len(vocab))]])\n",
    "    input_ = torch.LongTensor([[vocab.word2idx[\"<BOS>\"]]])\n",
    "    \n",
    "    # Generate continuation\n",
    "    for _ in range(max_len):\n",
    "        output, hidden = model(input_, hidden)\n",
    "        probs = output[-1].squeeze().div(temperature).exp()   # TODO: is this correct?\n",
    "        \n",
    "        if not allow_unk:\n",
    "            probs[vocab.word2idx[\"<UNK>\"]] = 0.\n",
    "            \n",
    "        if len(result) < min_len:\n",
    "            probs[vocab.word2idx[\"<EOS>\"]] = 0.\n",
    "        \n",
    "        token_index = sample_fn(probs)\n",
    "        input_.fill_(token_index)\n",
    "        \n",
    "        token = vocab.idx2word[token_index]\n",
    "        if token == \"<EOS>\":\n",
    "            break\n",
    "        result.append(token)\n",
    "        \n",
    "    return bpe_decode(\"\".join(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Y_J1eS3BfTF"
   },
   "outputs": [],
   "source": [
    "for temperature in (0.1, 0.3, 0.5, 0.8, 1.0, 1.5, 2.0, 3.0, 5.0):\n",
    "    print(f\"Sampling with temperature={temperature}\")\n",
    "    result = generate(model, vocab, simple_sample, temperature=temperature, allow_unk=False)\n",
    "    print(result)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ShTm-dddw6s9"
   },
   "outputs": [],
   "source": [
    "# –Ø–∫–µ –∑–Ω–∞—á–µ–Ω–Ω—è `temperature` –∑–¥–∞—î—Ç—å—Å—è –≤–∞–º –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ—é?\n",
    "report(\"best_temperature\", ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KO9-xZxRBkIB"
   },
   "source": [
    "## Top-k sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "HqPZTXxZCQdc"
   },
   "outputs": [],
   "source": [
    "def top_k_sampling(probs, k):\n",
    "    topk = probs.topk(k)\n",
    "    index = torch.multinomial(topk.values, num_samples=1)[0]\n",
    "#     print(f\"Top {k} words take {topk.values.sum():%} probability mass\")\n",
    "    return topk.indices[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q2BAZ9mnCRGC"
   },
   "outputs": [],
   "source": [
    "k = 15\n",
    "sample_fn = lambda probs: top_k_sampling(probs, k=k)\n",
    "for i in range(1, 10):\n",
    "    result = generate(model, vocab, sample_fn, allow_unk=False)\n",
    "    print(f\"#{i}: {result}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CuJFHRsaCoAK"
   },
   "source": [
    "## Nucleus (top-p) sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PUIZQgXhCU1l"
   },
   "outputs": [],
   "source": [
    "def nucleus_sampling(probs, max_p):\n",
    "    sorted_probs = probs.sort(descending=True)\n",
    "    cum_prob = 0.0\n",
    "    sample_indices = []\n",
    "    sample_probs = []\n",
    "    for i in range(0, len(sorted_probs.values)):\n",
    "        p = sorted_probs.values[i]\n",
    "        cum_prob += p\n",
    "        sample_probs.append(p)\n",
    "        sample_indices.append(sorted_probs.indices[i])\n",
    "        if cum_prob >= max_p:\n",
    "            break\n",
    "\n",
    "    index = torch.multinomial(torch.tensor(sample_probs), num_samples=1)\n",
    "    return sample_indices[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FXuy2S8tCq_Z"
   },
   "outputs": [],
   "source": [
    "for max_p in (0.1, 0.3, 0.5, 0.6, 0.8, 1.0):\n",
    "    sample_fn = lambda probs: nucleus_sampling(probs, max_p=max_p)\n",
    "    result = generate(model, vocab, sample_fn, allow_unk=False)\n",
    "    print(f\"#{max_p}: {result}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UJCQ6ZrivApx"
   },
   "outputs": [],
   "source": [
    "# –Ø–∫–µ –∑–Ω–∞—á–µ–Ω–Ω—è p –∑–¥–∞—î—Ç—å—Å—è –≤–∞–º –æ–ø—Ç–∏–º–∞–ª—å–Ω–∏–º?\n",
    "report(\"best_p\", ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ra-F6HyTCxcG"
   },
   "source": [
    "## Start from prompt\n",
    "\n",
    "–î–æ —Ü—å–æ–≥–æ –º–æ–º–µ–Ω—Ç—É –º–∏ –≥–µ–Ω–µ—Ä—É–≤–∞–ª–∏ —Ç–µ–∫—Å—Ç –∑ –Ω—É–ª—è. –û–¥–Ω–∞–∫ –∑–Ω–∞—á–Ω–æ –∫–æ—Ä–∏—Å–Ω—ñ—à–∏–º —î –∑–∞–¥–∞—á–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó —Ç–µ–∫—Å—Ç—É –≤—ñ–¥ –ø–µ–≤–Ω–æ–≥–æ –ø—Ä–µ—Ñ—ñ–∫—Å–∞ –∞–±–æ \"–ø—ñ–¥–∫–∞–∑–∫–∏\" -- –≤ –∞–Ω–≥–ª—ñ–π—Å—å–∫—ñ–π –º–æ–≤—ñ —Ü–µ –Ω–∞–∑–∏–≤–∞—î—Ç—å—Å—è \"prompt\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fccaVJA0DXPA"
   },
   "outputs": [],
   "source": [
    "!pip install youtokentome\n",
    "!wget http://134.209.248.229:8081/bpe.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dSDiAvTwDc-t"
   },
   "outputs": [],
   "source": [
    "import youtokentome\n",
    "bpe = youtokentome.BPE(\"bpe.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7mP3YWPfDI7Q"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate(model, vocab, sample_fn, max_len=50, temperature=1.0, allow_unk=True, prompt=None):\n",
    "    if prompt is None:\n",
    "        prompt = random.choice(vocab.idx2word)\n",
    "    prompt = [vocab.idx2word[x] for x in bpe.encode(prompt)]\n",
    "        \n",
    "    # force decode prompt\n",
    "    result = []\n",
    "    hidden = model.init_hidden(1)\n",
    "    for i, token in enumerate(prompt[:-1]):\n",
    "        index = vocab.word2idx[token]\n",
    "        input_ = torch.LongTensor([[index]])\n",
    "        output, hidden = model(input_, hidden)\n",
    "        \n",
    "    input_ = torch.LongTensor([[vocab.word2idx[prompt[-1]]]])\n",
    "    result = prompt[:]\n",
    "    \n",
    "    # Generate continuation\n",
    "    for _ in range(max_len):\n",
    "        output, hidden = model(input_, hidden)\n",
    "        probs = output[-1].squeeze().div(temperature).exp()\n",
    "        \n",
    "        if not allow_unk:\n",
    "            probs[vocab.word2idx[\"<UNK>\"]] = 0.\n",
    "        \n",
    "        token_index = sample_fn(probs)\n",
    "        input_.fill_(token_index)\n",
    "        \n",
    "        token = vocab.idx2word[token_index]\n",
    "        if token == \"<EOS>\":\n",
    "            break\n",
    "        result.append(token)\n",
    "        \n",
    "    return bpe_decode(\"\".join(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tBf2m-x7DJ0r"
   },
   "outputs": [],
   "source": [
    "k = 20\n",
    "sample_fn = lambda probs: top_k_sampling(probs, k=k)\n",
    "for i in range(1, 5):\n",
    "    # –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç —É–∫—Ä–∞—ó–Ω–∏\n",
    "    # —Ç–∞–∫–∞ –Ω–µ—Å–ø–æ–¥—ñ–≤–∞–Ω–∞ –∑–∞—è–≤–∞\n",
    "    result = generate(model, vocab, sample_fn, allow_unk=False, prompt=\"–º–∞–≥–∞–∑–∏–Ω–∏ –≤—ñ–¥–∫—Ä–∏–ª–∏ —Å–≤–æ—ó\")\n",
    "    print(f\"#{i}: {result}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qBd5PJlxP2i"
   },
   "source": [
    "–°–ø—Ä–æ–±—É–π—Ç–µ –ø—Ä–æ–¥–æ–≤–∂–∏—Ç–∏ —ñ–Ω—à—ñ –ø—Ä–µ—Ñ—ñ–∫—Å–∏:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MKCCCklFxF1a"
   },
   "outputs": [],
   "source": [
    "report(\"prompt1\", generate(model, vocab, sample_fn, allow_unk=False, prompt=\"—Å—Ç—É–¥–µ–Ω—Ç–∏ –∑—É—Å—Ç—Ä—ñ–ª–∏—Å—è –∑\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tiw3rFWuxOm4"
   },
   "outputs": [],
   "source": [
    "report(\"prompt2\", generate(model, vocab, sample_fn, allow_unk=False, prompt=\"–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç —É–∫—Ä–∞—ó–Ω–∏\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PCWIBDUhxY7D"
   },
   "outputs": [],
   "source": [
    "report(\"prompt3\", generate(model, vocab, sample_fn, allow_unk=False, prompt=\"—Ç–∞–∫–∞ –Ω–µ—Å–ø–æ–¥—ñ–≤–∞–Ω–∞ –∑–∞—è–≤–∞\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wCrC6qPfxgq2"
   },
   "source": [
    "–ü—Ä–∏–¥—É–º–∞–π—Ç–µ —Å–≤—ñ–π –ø–æ—á–∞—Ç–æ–∫ —Ä–µ—á–µ–Ω–Ω—è:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G7uJepzMxcWo"
   },
   "outputs": [],
   "source": [
    "report(\"prompt3\", generate(model, vocab, sample_fn, allow_unk=False, prompt=\"–í—Å–µ –±—É–¥–µ –¥–æ–±—Ä–µ\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mslGz69EDO7z"
   },
   "source": [
    "# Autocompletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0CsfNrIaHUPY"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def autocomplete(model, vocab, tokens, n=10):\n",
    "    if isinstance(tokens, str):\n",
    "        tokens = [vocab.idx2word[x] for x in bpe.encode(tokens)]\n",
    "\n",
    "    # force decode prompt\n",
    "    result = []\n",
    "    hidden = model.init_hidden(1)\n",
    "    for i, token in enumerate(tokens):\n",
    "        index = vocab.word2idx[token]\n",
    "        input_ = torch.LongTensor([[index]])\n",
    "        output, hidden = model(input_, hidden)\n",
    "    \n",
    "    topk = output.squeeze().topk(n)\n",
    "    words = [vocab.idx2word[x.item()] for x in topk.indices]\n",
    "    probs = [math.exp(p) for p in topk.values]\n",
    "    return list(zip(words, probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qeGddb44HhKs"
   },
   "outputs": [],
   "source": [
    "autocomplete(model, vocab, \"—Å—å–æ–≥–æ–¥–Ω—ñ —è –ø–æ–±–∞—á–∏–≤ –∫—ñ–ª—å–∫–∞\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F4mGy8OSI7h0"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def score_sentence(model, vocab, tokens):\n",
    "    if isinstance(tokens, str):\n",
    "        tokens = [\"<BOS>\"] + [vocab.idx2word[x] for x in bpe.encode(tokens)]\n",
    "        \n",
    "    probs = []\n",
    "\n",
    "    # force decode prompt\n",
    "    result = []\n",
    "    hidden = model.init_hidden(1)\n",
    "    for i, token in enumerate(tokens):\n",
    "        index = vocab.word2idx[token]\n",
    "        input_ = torch.LongTensor([[index]])\n",
    "        output, hidden = model(input_, hidden)\n",
    "        log_prob = output[-1].squeeze()[index]\n",
    "        print(f\"{token:<20} {log_prob.item()}\")\n",
    "        probs.append(log_prob.item())\n",
    "        \n",
    "    return sum(probs) / len(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cemwEiF1H0Cw"
   },
   "source": [
    "# Score sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fe6serIYI8Nk"
   },
   "outputs": [],
   "source": [
    "score_sentence(model, vocab, \"–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç —É–∫—Ä–∞—ó–Ω–∏ –±–æ—Ä—â\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2RGqKM9TJBQx"
   },
   "outputs": [],
   "source": [
    "score_sentence(model, vocab, \"–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç —É–∫—Ä–∞—ó–Ω–∏ –∑–∞—è–≤–∏–≤\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cuK8D9uQJR5c"
   },
   "outputs": [],
   "source": [
    "report(\"ALL DONE\", \"üí™\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab 4 - Text generation and LSTM (2022 Workbook)",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
